{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Cleaning and preprocessing text data for model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "os.makedirs('../data/processed', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (43410, 2) | Val: (5426, 2) | Test: (5427, 2)\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv('../data/raw/train_raw.csv')\n",
        "val_df = pd.read_csv('../data/raw/val_raw.csv')\n",
        "test_df = pd.read_csv('../data/raw/test_raw.csv')\n",
        "\n",
        "print(f\"Train: {train_df.shape} | Val: {val_df.shape} | Test: {test_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Raw Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  emotion\n",
              "0  My favourite food is anything I didn't have to...  neutral\n",
              "1  Now if he does off himself, everyone will thin...  neutral\n",
              "2                     WHY THE FUCK IS BAYLESS ISOING    anger\n",
              "3                        To make her feel threatened     fear\n",
              "4                             Dirty Southern Wankers    anger"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    \n",
        "    emoji_patterns = [\n",
        "        re.compile(u'[\\U0001F600-\\U0001F64F]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F300-\\U0001F5FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F680-\\U0001F6FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F1E0-\\U0001F1FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F900-\\U0001F9FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001FA00-\\U0001FA6F]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001FA70-\\U0001FAFF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U00002600-\\U000026FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U00002700-\\U000027BF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U000024C2-\\U0001F251]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F018-\\U0001F270]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F700-\\U0001F77F]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F780-\\U0001F7FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F800-\\U0001F8FF]', flags=re.UNICODE),\n",
        "    ]\n",
        "    \n",
        "    for pattern in emoji_patterns:\n",
        "        text = pattern.sub('', text)\n",
        "    \n",
        "    text = re.sub(u'[\\U0001F3FB-\\U0001F3FF]', '', text)\n",
        "    text = re.sub(u'[\\U0000200D]', '', text)\n",
        "    text = re.sub(u'[\\U0000FE00-\\U0000FE0F]', '', text)\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
        "    text = re.sub(r'r/\\w+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s!?.,:;\\-\\'\\\"()\\[\\]{}]', '', text)\n",
        "    text = re.sub(r'([!?.]){2,}', r'\\1', text)\n",
        "    text = re.sub(r'-{2,}', '-', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = re.sub(r'^[^\\w]+|[^\\w]+$', '', text)\n",
        "    \n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing complete\n"
          ]
        }
      ],
      "source": [
        "train_df['text_cleaned'] = train_df['text'].apply(preprocess_text)\n",
        "val_df['text_cleaned'] = val_df['text'].apply(preprocess_text)\n",
        "test_df['text_cleaned'] = test_df['text'].apply(preprocess_text)\n",
        "\n",
        "print(\"Preprocessing complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before/After Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example 1:\n",
            "  Before: My favourite food is anything I didn't have to cook myself.\n",
            "  After:  my favourite food is anything i didn't have to cook myself\n",
            "\n",
            "Example 2:\n",
            "  Before: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n",
            "  After:  now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n",
            "\n",
            "Example 3:\n",
            "  Before: WHY THE FUCK IS BAYLESS ISOING\n",
            "  After:  why the fuck is bayless isoing\n",
            "\n",
            "Example 4:\n",
            "  Before: To make her feel threatened\n",
            "  After:  to make her feel threatened\n",
            "\n",
            "Example 5:\n",
            "  Before: Dirty Southern Wankers\n",
            "  After:  dirty southern wankers\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"  Before: {train_df.iloc[i]['text']}\")\n",
        "    print(f\"  After:  {train_df.iloc[i]['text_cleaned']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove Short Texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Short texts (< 3 chars): Train=48, Val=4, Test=4\n",
            "After removal: Train=43362, Val=5422, Test=5423\n"
          ]
        }
      ],
      "source": [
        "train_empty = train_df[train_df['text_cleaned'].str.len() < 3].shape[0]\n",
        "val_empty = val_df[val_df['text_cleaned'].str.len() < 3].shape[0]\n",
        "test_empty = test_df[test_df['text_cleaned'].str.len() < 3].shape[0]\n",
        "\n",
        "print(f\"Short texts (< 3 chars): Train={train_empty}, Val={val_empty}, Test={test_empty}\")\n",
        "\n",
        "train_df = train_df[train_df['text_cleaned'].str.len() >= 3].reset_index(drop=True)\n",
        "val_df = val_df[val_df['text_cleaned'].str.len() >= 3].reset_index(drop=True)\n",
        "test_df = test_df[test_df['text_cleaned'].str.len() >= 3].reset_index(drop=True)\n",
        "\n",
        "print(f\"After removal: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned text stats:\n",
            "       cleaned_length  cleaned_word_count\n",
            "count    43362.000000        43362.000000\n",
            "mean        65.768830           12.635995\n",
            "std         36.171532            6.669857\n",
            "min          3.000000            1.000000\n",
            "25%         36.000000            7.000000\n",
            "50%         62.000000           12.000000\n",
            "75%         93.000000           18.000000\n",
            "max        703.000000           33.000000\n"
          ]
        }
      ],
      "source": [
        "train_df['cleaned_length'] = train_df['text_cleaned'].str.len()\n",
        "train_df['cleaned_word_count'] = train_df['text_cleaned'].str.split().str.len()\n",
        "\n",
        "print(\"Cleaned text stats:\")\n",
        "print(train_df[['cleaned_length', 'cleaned_word_count']].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Emotion Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          Count  Percentage\n",
            "emotion                    \n",
            "neutral   23238       53.59\n",
            "joy        9075       20.93\n",
            "anger      5335       12.30\n",
            "sadness    2371        5.47\n",
            "surprise   2149        4.96\n",
            "fear        615        1.42\n",
            "disgust     579        1.34\n",
            "\n",
            "Imbalance ratio: 40.13:1\n",
            "Note: Severe class imbalance - consider handling during training\n"
          ]
        }
      ],
      "source": [
        "emotion_counts = train_df['emotion'].value_counts()\n",
        "emotion_percentages = train_df['emotion'].value_counts(normalize=True) * 100\n",
        "\n",
        "emotion_df = pd.DataFrame({\n",
        "    'Count': emotion_counts,\n",
        "    'Percentage': emotion_percentages.round(2)\n",
        "})\n",
        "print(emotion_df)\n",
        "\n",
        "max_count = emotion_counts.max()\n",
        "min_count = emotion_counts.min()\n",
        "imbalance_ratio = max_count / min_count\n",
        "\n",
        "print(f\"\\nImbalance ratio: {imbalance_ratio:.2f}:1\")\n",
        "if imbalance_ratio > 3:\n",
        "    print(\"Note: Severe class imbalance - consider handling during training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Processed Datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed datasets: Train=(43362, 2), Val=(5422, 2), Test=(5423, 2)\n",
            "\n",
            "Sample:\n",
            "                                                text  emotion\n",
            "0  my favourite food is anything i didn't have to...  neutral\n",
            "1  now if he does off himself, everyone will thin...  neutral\n",
            "2                     why the fuck is bayless isoing    anger\n",
            "3                        to make her feel threatened     fear\n",
            "4                             dirty southern wankers    anger\n"
          ]
        }
      ],
      "source": [
        "train_processed = train_df[['text_cleaned', 'emotion']].copy()\n",
        "train_processed.columns = ['text', 'emotion']\n",
        "\n",
        "val_processed = val_df[['text_cleaned', 'emotion']].copy()\n",
        "val_processed.columns = ['text', 'emotion']\n",
        "\n",
        "test_processed = test_df[['text_cleaned', 'emotion']].copy()\n",
        "test_processed.columns = ['text', 'emotion']\n",
        "\n",
        "print(f\"Processed datasets: Train={train_processed.shape}, Val={val_processed.shape}, Test={test_processed.shape}\")\n",
        "print(\"\\nSample:\")\n",
        "print(train_processed.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Processed Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved processed datasets\n"
          ]
        }
      ],
      "source": [
        "train_processed.to_csv('../data/processed/train_processed.csv', index=False)\n",
        "val_processed.to_csv('../data/processed/val_processed.csv', index=False)\n",
        "test_processed.to_csv('../data/processed/test_processed.csv', index=False)\n",
        "\n",
        "print(\"Saved processed datasets\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Label Encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emotion to ID mapping:\n",
            "  anger: 0\n",
            "  disgust: 1\n",
            "  fear: 2\n",
            "  joy: 3\n",
            "  neutral: 4\n",
            "  sadness: 5\n",
            "  surprise: 6\n",
            "\n",
            "Saved to emotion_mapping.json\n"
          ]
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_processed['emotion'])\n",
        "\n",
        "emotion_to_id = {emotion: idx for idx, emotion in enumerate(label_encoder.classes_)}\n",
        "id_to_emotion = {idx: emotion for emotion, idx in emotion_to_id.items()}\n",
        "\n",
        "print(\"Emotion to ID mapping:\")\n",
        "for emotion, idx in emotion_to_id.items():\n",
        "    print(f\"  {emotion}: {idx}\")\n",
        "\n",
        "with open('../data/processed/emotion_mapping.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'emotion_to_id': emotion_to_id,\n",
        "        'id_to_emotion': id_to_emotion\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved to emotion_mapping.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing Summary:\n",
            "Total samples: 54,207\n",
            "Train: 43,362 | Val: 5,422 | Test: 5,423\n",
            "\n",
            "Avg text length: 66 chars, 12.6 words\n",
            "\n",
            "Emotion distribution:\n",
            "  neutral   : 23,238 (53.59%)\n",
            "  joy       :  9,075 (20.93%)\n",
            "  anger     :  5,335 (12.30%)\n",
            "  sadness   :  2,371 ( 5.47%)\n",
            "  surprise  :  2,149 ( 4.96%)\n",
            "  fear      :    615 ( 1.42%)\n",
            "  disgust   :    579 ( 1.34%)\n",
            "\n",
            "Files saved: train_processed.csv, val_processed.csv, test_processed.csv, emotion_mapping.json\n"
          ]
        }
      ],
      "source": [
        "print(\"Preprocessing Summary:\")\n",
        "print(f\"Total samples: {len(train_processed) + len(val_processed) + len(test_processed):,}\")\n",
        "print(f\"Train: {len(train_processed):,} | Val: {len(val_processed):,} | Test: {len(test_processed):,}\")\n",
        "print(f\"\\nAvg text length: {train_processed['text'].str.len().mean():.0f} chars, {train_processed['text'].str.split().str.len().mean():.1f} words\")\n",
        "print(f\"\\nEmotion distribution:\")\n",
        "for emotion, count in emotion_counts.items():\n",
        "    percentage = (count / len(train_processed)) * 100\n",
        "    print(f\"  {emotion:10s}: {count:6,} ({percentage:5.2f}%)\")\n",
        "print(f\"\\nFiles saved: train_processed.csv, val_processed.csv, test_processed.csv, emotion_mapping.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
