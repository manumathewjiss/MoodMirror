{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset\n",
    "\n",
    "Download and prepare the GoEmotions dataset from HuggingFace. Maps 27 emotions to 7 simplified categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/manumathewjiss/Documents/Darsh NLP project/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"go_emotions\", \"simplified\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 43,410 | Val: 5,426 | Test: 5,427\n",
      "Total: 54,263\n",
      "Columns: ['text', 'labels', 'id']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(dataset['train']):,} | Val: {len(dataset['validation']):,} | Test: {len(dataset['test']):,}\")\n",
    "print(f\"Total: {len(dataset['train']) + len(dataset['validation']) + len(dataset['test']):,}\")\n",
    "print(f\"Columns: {dataset['train'].column_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (43410, 3) | Val: (5426, 3) | Test: (5427, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(dataset['train'])\n",
    "val_df = pd.DataFrame(dataset['validation'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "print(f\"Train: {train_df.shape} | Val: {val_df.shape} | Test: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map to 7 Emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_7_emotions(labels):\n",
    "    if len(labels) == 0:\n",
    "        return 'neutral'\n",
    "    label = labels[0]\n",
    "    if label in [17, 1, 15, 20, 4, 21, 23]:\n",
    "        return 'joy'\n",
    "    elif label in [25, 9, 16, 24]:\n",
    "        return 'sadness'\n",
    "    elif label in [2, 3, 10]:\n",
    "        return 'anger'\n",
    "    elif label in [14, 19]:\n",
    "        return 'fear'\n",
    "    elif label in [26, 13, 22]:\n",
    "        return 'surprise'\n",
    "    elif label in [11]:\n",
    "        return 'disgust'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "train_df['emotion'] = train_df['labels'].apply(map_to_7_emotions)\n",
    "val_df['emotion'] = val_df['labels'].apply(map_to_7_emotions)\n",
    "test_df['emotion'] = test_df['labels'].apply(map_to_7_emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0  My favourite food is anything I didn't have to...  neutral\n",
       "1  Now if he does off himself, everyone will thin...  neutral\n",
       "2                     WHY THE FUCK IS BAYLESS ISOING    anger\n",
       "3                        To make her feel threatened     fear\n",
       "4                             Dirty Southern Wankers    anger"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[['text', 'emotion']]\n",
    "val_df = val_df[['text', 'emotion']]\n",
    "test_df = test_df[['text', 'emotion']]\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved datasets\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('../data/raw', exist_ok=True)\n",
    "\n",
    "train_df.to_csv('../data/raw/train_raw.csv', index=False)\n",
    "val_df.to_csv('../data/raw/val_raw.csv', index=False)\n",
    "test_df.to_csv('../data/raw/test_raw.csv', index=False)\n",
    "\n",
    "print(\"Saved datasets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary:\n",
      "Total samples: 54,263\n",
      "Train: 43,410 | Val: 5,426 | Test: 5,427\n",
      "\n",
      "Emotions: ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
      "\n",
      "Files saved: train_raw.csv, val_raw.csv, test_raw.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Summary:\")\n",
    "print(f\"Total samples: {len(train_df) + len(val_df) + len(test_df):,}\")\n",
    "print(f\"Train: {len(train_df):,} | Val: {len(val_df):,} | Test: {len(test_df):,}\")\n",
    "print(f\"\\nEmotions: {sorted(train_df['emotion'].unique())}\")\n",
    "print(f\"\\nFiles saved: train_raw.csv, val_raw.csv, test_raw.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
