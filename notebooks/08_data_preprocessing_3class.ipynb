{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing - 3-Class Emotion Classification\n",
        "\n",
        "Cleaning, preprocessing, and balancing text data for 3-class emotion classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "os.makedirs('../data/processed', exist_ok=True)\n",
        "\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (43410, 2) | Val: (5426, 2) | Test: (5427, 2)\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv('../data/raw/train_raw.csv')\n",
        "val_df = pd.read_csv('../data/raw/val_raw.csv')\n",
        "test_df = pd.read_csv('../data/raw/test_raw.csv')\n",
        "\n",
        "print(f\"Train: {train_df.shape} | Val: {val_df.shape} | Test: {test_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Raw Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  emotion\n",
              "0  My favourite food is anything I didn't have to...  neutral\n",
              "1  Now if he does off himself, everyone will thin...  neutral\n",
              "2                     WHY THE FUCK IS BAYLESS ISOING    anger\n",
              "3                        To make her feel threatened     fear\n",
              "4                             Dirty Southern Wankers    anger"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    \n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    \n",
        "    emoji_patterns = [\n",
        "        re.compile(u'[\\U0001F600-\\U0001F64F]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F300-\\U0001F5FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F680-\\U0001F6FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F1E0-\\U0001F1FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F900-\\U0001F9FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001FA00-\\U0001FA6F]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001FA70-\\U0001FAFF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U00002600-\\U000026FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U00002700-\\U000027BF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U000024C2-\\U0001F251]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F018-\\U0001F270]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F700-\\U0001F77F]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F780-\\U0001F7FF]', flags=re.UNICODE),\n",
        "        re.compile(u'[\\U0001F800-\\U0001F8FF]', flags=re.UNICODE),\n",
        "    ]\n",
        "    \n",
        "    for pattern in emoji_patterns:\n",
        "        text = pattern.sub('', text)\n",
        "    \n",
        "    text = re.sub(u'[\\U0001F3FB-\\U0001F3FF]', '', text)\n",
        "    text = re.sub(u'[\\U0000200D]', '', text)\n",
        "    text = re.sub(u'[\\U0000FE00-\\U0000FE0F]', '', text)\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
        "    text = re.sub(r'r/\\w+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s!?.,:;\\-\\'\\\"()\\[\\]{}]', '', text)\n",
        "    text = re.sub(r'([!?.]){2,}', r'\\1', text)\n",
        "    text = re.sub(r'-{2,}', '-', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = re.sub(r'^[^\\w]+|[^\\w]+$', '', text)\n",
        "    \n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing complete\n"
          ]
        }
      ],
      "source": [
        "train_df['text_cleaned'] = train_df['text'].apply(preprocess_text)\n",
        "val_df['text_cleaned'] = val_df['text'].apply(preprocess_text)\n",
        "test_df['text_cleaned'] = test_df['text'].apply(preprocess_text)\n",
        "\n",
        "print(\"Preprocessing complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before/After Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example 1:\n",
            "  Before: My favourite food is anything I didn't have to cook myself.\n",
            "  After:  my favourite food is anything i didn't have to cook myself\n",
            "\n",
            "Example 2:\n",
            "  Before: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n",
            "  After:  now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n",
            "\n",
            "Example 3:\n",
            "  Before: WHY THE FUCK IS BAYLESS ISOING\n",
            "  After:  why the fuck is bayless isoing\n",
            "\n",
            "Example 4:\n",
            "  Before: To make her feel threatened\n",
            "  After:  to make her feel threatened\n",
            "\n",
            "Example 5:\n",
            "  Before: Dirty Southern Wankers\n",
            "  After:  dirty southern wankers\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"  Before: {train_df.iloc[i]['text']}\")\n",
        "    print(f\"  After:  {train_df.iloc[i]['text_cleaned']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Remove Short Texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Short texts (< 3 chars): Train=48, Val=4, Test=4\n",
            "After removal: Train=43362, Val=5422, Test=5423\n"
          ]
        }
      ],
      "source": [
        "train_empty = train_df[train_df['text_cleaned'].str.len() < 3].shape[0]\n",
        "val_empty = val_df[val_df['text_cleaned'].str.len() < 3].shape[0]\n",
        "test_empty = test_df[test_df['text_cleaned'].str.len() < 3].shape[0]\n",
        "\n",
        "print(f\"Short texts (< 3 chars): Train={train_empty}, Val={val_empty}, Test={test_empty}\")\n",
        "\n",
        "train_df = train_df[train_df['text_cleaned'].str.len() >= 3].reset_index(drop=True)\n",
        "val_df = val_df[val_df['text_cleaned'].str.len() >= 3].reset_index(drop=True)\n",
        "test_df = test_df[test_df['text_cleaned'].str.len() >= 3].reset_index(drop=True)\n",
        "\n",
        "print(f\"After removal: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3-Class Emotion Mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3-class mapping applied\n",
            "Classes: ['negative', 'neutral', 'positive']\n"
          ]
        }
      ],
      "source": [
        "mapping_7_to_3 = {\n",
        "    'anger': 'negative',\n",
        "    'disgust': 'negative',\n",
        "    'fear': 'negative',\n",
        "    'sadness': 'negative',\n",
        "    'joy': 'positive',\n",
        "    'neutral': 'neutral',\n",
        "    'surprise': 'neutral'\n",
        "}\n",
        "\n",
        "train_df['emotion'] = train_df['emotion'].map(mapping_7_to_3)\n",
        "val_df['emotion'] = val_df['emotion'].map(mapping_7_to_3)\n",
        "test_df['emotion'] = test_df['emotion'].map(mapping_7_to_3)\n",
        "\n",
        "print(\"3-class mapping applied\")\n",
        "print(f\"Classes: {sorted(train_df['emotion'].unique())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class Distribution Before Balancing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before balancing:\n",
            "          Count  Percentage\n",
            "emotion                    \n",
            "neutral   25387       58.55\n",
            "positive   9075       20.93\n",
            "negative   8900       20.52\n",
            "\n",
            "Imbalance ratio: 2.85:1\n"
          ]
        }
      ],
      "source": [
        "emotion_counts_before = train_df['emotion'].value_counts()\n",
        "emotion_percentages_before = train_df['emotion'].value_counts(normalize=True) * 100\n",
        "\n",
        "emotion_df_before = pd.DataFrame({\n",
        "    'Count': emotion_counts_before,\n",
        "    'Percentage': emotion_percentages_before.round(2)\n",
        "})\n",
        "print(\"Before balancing:\")\n",
        "print(emotion_df_before)\n",
        "\n",
        "max_count = emotion_counts_before.max()\n",
        "min_count = emotion_counts_before.min()\n",
        "imbalance_ratio = max_count / min_count\n",
        "\n",
        "print(f\"\\nImbalance ratio: {imbalance_ratio:.2f}:1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Balance Classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Balancing TRAIN dataset...\n",
            "Target per class: 14,454 samples\n",
            "Original distribution:\n",
            "  negative  :  8,900 samples\n",
            "  neutral   : 25,387 samples\n",
            "  positive  :  9,075 samples\n",
            "  negative  : oversampled 5,554 samples\n",
            "  neutral   : undersampled 10,933 samples\n",
            "  positive  : oversampled 5,379 samples\n",
            "\n",
            "After balancing:\n",
            "  negative  : 14,454 samples\n",
            "  neutral   : 14,454 samples\n",
            "  positive  : 14,454 samples\n",
            "  Total: 43,362 samples\n",
            "\n",
            "Balancing VALIDATION dataset...\n",
            "Target per class: 1,807 samples\n",
            "Original distribution:\n",
            "  negative  :  1,114 samples\n",
            "  neutral   :  3,088 samples\n",
            "  positive  :  1,220 samples\n",
            "  negative  : oversampled 693 samples\n",
            "  neutral   : undersampled 1,281 samples\n",
            "  positive  : oversampled 587 samples\n",
            "\n",
            "After balancing:\n",
            "  negative  :  1,807 samples\n",
            "  neutral   :  1,807 samples\n",
            "  positive  :  1,807 samples\n",
            "  Total: 5,421 samples\n",
            "\n",
            "Balancing TEST dataset...\n",
            "Target per class: 1,807 samples\n",
            "Original distribution:\n",
            "  negative  :  1,164 samples\n",
            "  neutral   :  3,150 samples\n",
            "  positive  :  1,109 samples\n",
            "  negative  : oversampled 643 samples\n",
            "  neutral   : undersampled 1,343 samples\n",
            "  positive  : oversampled 698 samples\n",
            "\n",
            "After balancing:\n",
            "  negative  :  1,807 samples\n",
            "  neutral   :  1,807 samples\n",
            "  positive  :  1,807 samples\n",
            "  Total: 5,421 samples\n"
          ]
        }
      ],
      "source": [
        "def balance_dataset(df, split_name):\n",
        "    print(f\"\\nBalancing {split_name} dataset...\")\n",
        "    \n",
        "    emotion_counts = Counter(df['emotion'])\n",
        "    mean_samples = int(np.mean(list(emotion_counts.values())))\n",
        "    \n",
        "    print(f\"Target per class: {mean_samples:,} samples\")\n",
        "    print(f\"Original distribution:\")\n",
        "    for emotion, count in sorted(emotion_counts.items()):\n",
        "        print(f\"  {emotion:10s}: {count:6,} samples\")\n",
        "    \n",
        "    balanced_rows = []\n",
        "    for emotion in sorted(df['emotion'].unique()):\n",
        "        class_data = df[df['emotion'] == emotion].copy()\n",
        "        class_count = len(class_data)\n",
        "        \n",
        "        if class_count < mean_samples:\n",
        "            needed = mean_samples - class_count\n",
        "            oversample_indices = np.random.choice(class_data.index, size=needed, replace=True)\n",
        "            oversampled = class_data.loc[oversample_indices]\n",
        "            balanced_class = pd.concat([class_data, oversampled], ignore_index=True)\n",
        "            print(f\"  {emotion:10s}: oversampled {needed:,} samples\")\n",
        "        elif class_count > mean_samples:\n",
        "            balanced_class = class_data.sample(n=mean_samples, random_state=42).reset_index(drop=True)\n",
        "            removed = class_count - mean_samples\n",
        "            print(f\"  {emotion:10s}: undersampled {removed:,} samples\")\n",
        "        else:\n",
        "            balanced_class = class_data.reset_index(drop=True)\n",
        "            print(f\"  {emotion:10s}: no change\")\n",
        "        \n",
        "        balanced_rows.append(balanced_class)\n",
        "    \n",
        "    df_balanced = pd.concat(balanced_rows, ignore_index=True)\n",
        "    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    \n",
        "    balanced_counts = Counter(df_balanced['emotion'])\n",
        "    print(f\"\\nAfter balancing:\")\n",
        "    for emotion, count in sorted(balanced_counts.items()):\n",
        "        print(f\"  {emotion:10s}: {count:6,} samples\")\n",
        "    print(f\"  Total: {len(df_balanced):,} samples\")\n",
        "    \n",
        "    return df_balanced\n",
        "\n",
        "train_balanced = balance_dataset(train_df, \"TRAIN\")\n",
        "val_balanced = balance_dataset(val_df, \"VALIDATION\")\n",
        "test_balanced = balance_dataset(test_df, \"TEST\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Processed Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed datasets: Train=(43362, 2), Val=(5421, 2), Test=(5421, 2)\n",
            "\n",
            "Sample:\n",
            "                                                text   emotion\n",
            "0                                   shes all natural   neutral\n",
            "1  no, hes been with more women than i have been ...  negative\n",
            "2  thanks for the quick reply i am very bored. wh...  positive\n",
            "3                                    except is worse  negative\n",
            "4                                          fake lous  negative\n"
          ]
        }
      ],
      "source": [
        "train_processed = train_balanced[['text_cleaned', 'emotion']].copy()\n",
        "train_processed.columns = ['text', 'emotion']\n",
        "\n",
        "val_processed = val_balanced[['text_cleaned', 'emotion']].copy()\n",
        "val_processed.columns = ['text', 'emotion']\n",
        "\n",
        "test_processed = test_balanced[['text_cleaned', 'emotion']].copy()\n",
        "test_processed.columns = ['text', 'emotion']\n",
        "\n",
        "print(f\"Processed datasets: Train={train_processed.shape}, Val={val_processed.shape}, Test={test_processed.shape}\")\n",
        "print(\"\\nSample:\")\n",
        "print(train_processed.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Processed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved processed 3-class datasets\n"
          ]
        }
      ],
      "source": [
        "train_processed.to_csv('../data/processed/train_processed_3class.csv', index=False)\n",
        "val_processed.to_csv('../data/processed/val_processed_3class.csv', index=False)\n",
        "test_processed.to_csv('../data/processed/test_processed_3class.csv', index=False)\n",
        "\n",
        "print(\"Saved processed 3-class datasets\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Emotion Mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3-Class Emotion to ID mapping:\n",
            "  negative: 0\n",
            "  neutral: 1\n",
            "  positive: 2\n",
            "\n",
            "Saved to emotion_mapping_3class.json\n"
          ]
        }
      ],
      "source": [
        "emotion_to_id = {\n",
        "    'negative': 0,\n",
        "    'neutral': 1,\n",
        "    'positive': 2\n",
        "}\n",
        "\n",
        "id_to_emotion = {idx: emotion for emotion, idx in emotion_to_id.items()}\n",
        "\n",
        "print(\"3-Class Emotion to ID mapping:\")\n",
        "for emotion, idx in emotion_to_id.items():\n",
        "    print(f\"  {emotion}: {idx}\")\n",
        "\n",
        "with open('../data/processed/emotion_mapping_3class.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'emotion_to_id': emotion_to_id,\n",
        "        'id_to_emotion': {str(k): v for k, v in id_to_emotion.items()}\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved to emotion_mapping_3class.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3-Class Preprocessing Summary:\n",
            "Total samples: 54,204\n",
            "Train: 43,362 | Val: 5,421 | Test: 5,421\n",
            "\n",
            "Avg text length: 66 chars, 12.8 words\n",
            "\n",
            "Balanced emotion distribution:\n",
            "  negative  : 14,454 (33.33%)\n",
            "  neutral   : 14,454 (33.33%)\n",
            "  positive  : 14,454 (33.33%)\n",
            "\n",
            "Files saved:\n",
            "  - train_processed_3class.csv\n",
            "  - val_processed_3class.csv\n",
            "  - test_processed_3class.csv\n",
            "  - emotion_mapping_3class.json\n"
          ]
        }
      ],
      "source": [
        "final_counts = train_processed['emotion'].value_counts()\n",
        "\n",
        "print(\"3-Class Preprocessing Summary:\")\n",
        "print(f\"Total samples: {len(train_processed) + len(val_processed) + len(test_processed):,}\")\n",
        "print(f\"Train: {len(train_processed):,} | Val: {len(val_processed):,} | Test: {len(test_processed):,}\")\n",
        "print(f\"\\nAvg text length: {train_processed['text'].str.len().mean():.0f} chars, {train_processed['text'].str.split().str.len().mean():.1f} words\")\n",
        "print(f\"\\nBalanced emotion distribution:\")\n",
        "for emotion, count in sorted(final_counts.items()):\n",
        "    percentage = (count / len(train_processed)) * 100\n",
        "    print(f\"  {emotion:10s}: {count:6,} ({percentage:5.2f}%)\")\n",
        "print(f\"\\nFiles saved:\")\n",
        "print(f\"  - train_processed_3class.csv\")\n",
        "print(f\"  - val_processed_3class.csv\")\n",
        "print(f\"  - test_processed_3class.csv\")\n",
        "print(f\"  - emotion_mapping_3class.json\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
