# MoodMirror: Emotion Detection from Text using NLP

**NLP Final Project - Academic Implementation**

---

## ğŸ“‹ Project Overview

**MoodMirror** is an AI-powered emotion detection system that analyzes text to identify and classify human emotions. This project demonstrates the complete Machine Learning pipeline from data collection to model deployment.

### **Problem Statement**
Understanding emotions in text is crucial for applications like mental health monitoring, customer feedback analysis, and social media sentiment tracking. This project builds a multi-class emotion classifier that can detect 7 distinct emotions from user-written text.

### **Emotions Detected**
- Joy
- Sadness
- Anger
- Fear
- Surprise
- Disgust
- Neutral

---

## ğŸ¯ Project Objectives

1. **Data Collection**: Gather and prepare emotion-labeled text dataset
2. **Data Preprocessing**: Clean, tokenize, and prepare text for training
3. **Model Training**: Train multiple ML/DL models for emotion classification
4. **Model Evaluation**: Compare models using accuracy, precision, recall, F1-score
5. **Deployment**: Build REST API for real-time emotion detection
6. **Analysis**: Provide insights and recommendations for improvement

---

## ğŸ“ Project Structure

```
MoodMirror/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original datasets
â”‚   â””â”€â”€ processed/              # Cleaned and preprocessed data
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb       # EDA and visualization
â”‚   â”œâ”€â”€ 02_data_preprocessing.ipynb     # Data cleaning and preparation
â”‚   â”œâ”€â”€ 03_baseline_models.ipynb        # Traditional ML models
â”‚   â”œâ”€â”€ 04_deep_learning_models.ipynb   # LSTM, BERT fine-tuning
â”‚   â””â”€â”€ 05_model_evaluation.ipynb       # Comparison and analysis
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preparation/       # Data loading and preprocessing scripts
â”‚   â”œâ”€â”€ model_training/         # Training scripts for different models
â”‚   â”œâ”€â”€ evaluation/             # Evaluation metrics and visualization
â”‚   â””â”€â”€ deployment/             # FastAPI application for deployment
â”œâ”€â”€ models/                     # Saved trained models
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/                # Plots and visualizations
â”‚   â”œâ”€â”€ metrics/                # Performance metrics (JSON/CSV)
â”‚   â””â”€â”€ models/                 # Model comparison results
â”œâ”€â”€ tests/                      # Unit tests
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ report.pdf              # Academic report
â”‚   â””â”€â”€ presentation.pptx       # Final presentation
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

---

## ğŸš€ Getting Started

### **Prerequisites**
- Python 3.8+
- pip or conda
- Jupyter Notebook
- Git

### **Installation**

1. **Clone the repository**
```bash
cd "Darsh NLP project"
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download dataset** (instructions in notebooks/01_data_exploration.ipynb)

---

## ğŸ“Š Dataset

**Primary Dataset**: GoEmotions Dataset (Google Research)
- **Size**: 58,000+ carefully curated text samples
- **Source**: Reddit comments
- **Labels**: 27 emotion categories (we'll map to 7 main emotions)
- **Split**: 80% train, 10% validation, 10% test

**Alternative/Supplementary Datasets**:
- Emotion Dataset for NLP (Kaggle)
- DailyDialog Dataset
- EmoContext (SemEval 2019)

---

## ğŸ§ª Methodology

### **Phase 1: Data Preparation (Teammate 1)**
- Data collection and exploration
- Text cleaning and preprocessing
- Train/validation/test split
- Data augmentation (optional)

### **Phase 2: Model Development (Both)**
- **Baseline Models**:
  - Naive Bayes
  - Logistic Regression
  - Support Vector Machine (SVM)
  
- **Deep Learning Models**:
  - LSTM with Word2Vec embeddings
  - BiLSTM with attention
  - DistilBERT (fine-tuned)

### **Phase 3: Evaluation (Teammate 2)**
- Performance metrics calculation
- Confusion matrix analysis
- Error analysis
- Model comparison

### **Phase 4: Deployment (Both)**
- FastAPI REST API
- Model serving
- Testing and documentation

---

## ğŸ“ˆ Expected Results

### **Performance Targets**
- Baseline Model: 60-70% accuracy
- Deep Learning Models: 80-90% accuracy
- Final Model: 85%+ accuracy with good F1-scores across all classes

### **Deliverables**
1. âœ… Complete codebase (Jupyter notebooks + Python scripts)
2. âœ… Trained models (saved in `models/` directory)
3. âœ… Evaluation report with metrics and visualizations
4. âœ… REST API for real-time predictions
5. âœ… Academic report (PDF)
6. âœ… Presentation slides (PPTX)
7. âœ… Dataset (included or download links)

---

## ğŸ”§ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Language** | Python 3.8+ |
| **Data Processing** | pandas, numpy, nltk, spaCy |
| **Visualization** | matplotlib, seaborn, plotly |
| **ML Models** | scikit-learn |
| **Deep Learning** | PyTorch, Transformers (HuggingFace) |
| **API** | FastAPI, uvicorn |
| **Experiment Tracking** | Weights & Biases / MLflow (optional) |

---

## ğŸ‘¥ Team & Task Division

### **Team Member 1: [Your Name]**
**Responsibilities**:
- Data collection and exploration (Notebook 01)
- Data preprocessing pipeline (Notebook 02)
- Baseline model implementation (Notebook 03)
- API deployment (src/deployment)
- README and documentation

### **Team Member 2: [Teammate Name]**
**Responsibilities**:
- Deep learning models (Notebook 04)
- Model evaluation and comparison (Notebook 05)
- Visualization and results analysis
- Academic report writing
- Presentation slides creation

**Collaborative Tasks**:
- Code review and testing
- Results discussion
- Final presentation preparation
- ZIP file compilation for submission

---

## ğŸ“ Usage

### **Training Models**

```bash
# Train baseline models
python src/model_training/train_baseline.py

# Train LSTM model
python src/model_training/train_lstm.py

# Fine-tune BERT
python src/model_training/train_bert.py
```

### **Evaluation**

```bash
# Evaluate all models
python src/evaluation/evaluate_models.py

# Generate comparison report
python src/evaluation/generate_report.py
```

### **Running the API**

```bash
# Start FastAPI server
cd src/deployment
uvicorn app:app --reload

# API will be available at: http://localhost:8000
# Documentation at: http://localhost:8000/docs
```

### **API Example**

```bash
# Predict emotion
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"text": "I am so excited about this project!"}'

# Response:
{
  "emotion": "joy",
  "confidence": 0.92,
  "all_probabilities": {
    "joy": 0.92,
    "surprise": 0.05,
    "neutral": 0.02,
    "sadness": 0.01
  }
}
```

---

## ğŸ“Š Results Preview

### Baseline Model Results

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| Logistic Regression (Baseline) | 53.66% | 61.79% | 53.66% | 55.56% |
| DistilBERT | TBD | TBD | TBD | TBD |

**Note:** Baseline model uses TF-IDF features with mean-based class balancing (SMOTE + RandomUnderSampler).

---

## ğŸ” Key Insights & Improvements

*(Will be added after analysis)*

### **Challenges Faced**
- TBD

### **What Worked Well**
- TBD

### **Future Improvements**
- Multi-modal emotion detection (text + audio + video)
- Real-time emotion tracking dashboard
- Personalized emotion analysis
- Explainable AI for emotion predictions

---

## ğŸ“š References

1. GoEmotions Dataset: https://github.com/google-research/google-research/tree/master/goemotions
2. Emotion Detection Papers: [Will add]
3. HuggingFace Transformers: https://huggingface.co/docs/transformers

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ“ Academic Information

**Course**: Natural Language Processing  
**Institution**: [Your University]  
**Semester**: [Current Semester]  
**Submission Date**: [Date]

---

**Status**: ğŸš§ In Development

**Last Updated**: November 26, 2025

